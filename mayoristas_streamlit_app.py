# -*- coding: utf-8 -*-
"""
Created on Tue May 20 17:35:02 2025

@author: User
"""

import streamlit as st
import pandas as pd
import requests
import io
from datetime import datetime
from datetime import timedelta
import dropbox
st.set_page_config(page_title="Conciliaciones Mayoristas", layout="wide")
# Crea un cliente de Dropbox usando tu token de Secrets
cfg_dbx = st.secrets["dropbox"]
dbx = dropbox.Dropbox(
    app_key=cfg_dbx["app_key"],
    app_secret=cfg_dbx["app_secret"],
    oauth2_refresh_token=cfg_dbx["refresh_token"],
)
def upload_to_dropbox(data: bytes):
    """Sube (o sobrescribe) un archivo a Dropbox."""
    cfg = st.secrets["dropbox"]
    try:
        dbx.files_upload(
            data,
            cfg["remote_path"],
            mode=dropbox.files.WriteMode.overwrite
        )
        st.success("‚úÖ Hist√≥rico subido a Dropbox")
    except Exception as e:
        st.error(f"‚ùå Error subiendo a Dropbox: {e}")



# ‚Äî 1) Egresos (Compras) ‚Äî
@st.cache_data
def procesar_egresos(df: pd.DataFrame) -> dict[str, pd.DataFrame]:
    casilleros = ["9444", "14856", "11591", "1444", "1633"]
    df = df.copy()
    df["Fecha Compra"] = pd.to_datetime(df["Fecha Compra"], errors="coerce", utc=True)
    df["Fecha Compra"] = df["Fecha Compra"].dt.tz_convert(None).dt.strftime("%Y-%m-%d")
    df["Casillero"] = df["Casillero"].astype(str)
    df = df[df["Casillero"].isin(casilleros)]
    df["Tipo"] = "Egreso"
    df["Total de Pago COP"] = pd.to_numeric(df["Total de Pago COP"], errors="coerce")
    df["Valor de compra COP"] = pd.to_numeric(df["Valor de compra COP"], errors="coerce")
    mask = (df["Estado de Orden"] == "Cancelada") & df["Total de Pago COP"].isna()
    df.loc[mask, "Total de Pago COP"] = df.loc[mask, "Valor de compra COP"]
    df["Orden"] = pd.to_numeric(df["Orden"], errors="coerce").astype("Int64")
    df = df.sort_values("Orden")
    df["Orden"] = df["Orden"].astype(str)
    df["Monto"] = df.apply(
    lambda row: row["Valor de compra USD"] if row["Casillero"] in ["1444", "14856"] else row["Valor de compra COP"],
    axis=1
    )
    df = df.rename(columns={
        "Fecha Compra": "Fecha"
    })[["Fecha","Tipo","Monto","Orden","TRM","Usuario","Casillero","Estado de Orden","Nombre del producto"]]
    df.loc[df["Casillero"]=="9444","Usuario"] = "Maira Alejandra Paez"
    salida = {}
    for cas in casilleros:
        salida[f"egresos_{cas}"] = df[df["Casillero"]==cas].reset_index(drop=True)
    return salida

# ‚Äî 2) Ingresos Extra ‚Äî
@st.cache_data
def procesar_ingresos_extra(hojas: dict[str, pd.DataFrame]) -> dict[str, pd.DataFrame]:
    resultado = {}
    for hoja, df in (hojas or {}).items():
        cas = hoja.split("-")[0].strip()
        if not cas.isdigit(): continue
        df2 = df.copy()
        if "Casillero" in df2.columns:
            df2["Casillero"] = df2["Casillero"].astype(str)
        else:
            df2["Casillero"] = cas
        if "Fecha" in df2.columns:
            try:
                fmax = pd.to_datetime(df2["Fecha"]).max().strftime("%Y-%m-%d")
                url = f"https://www.datos.gov.co/resource/mcec-87by.json?vigenciadesde={fmax}T00:00:00.000"
                data = requests.get(url).json()
                trm = float(data[0]["valor"]) if data and "valor" in data[0] else None
            except:
                trm = None
            df2["TRM"] = trm
        resultado[f"extra_{cas}"] = df2.reset_index(drop=True)
    return resultado

# ‚Äî 3+4) Ingresos Cliente Gen√©rico ‚Äî
@st.cache_data



# 1) Tu funci√≥n original para los .xls (TSV renombrado)
def procesar_ingresos_clientes_xls(files: list[bytes], usuario: str, casillero: str) -> pd.DataFrame:
      dfs = []
      for up in files:
          df = pd.read_csv(up, sep="\t", encoding="latin-1", engine="python")
          df["Archivo_Origen"] = up.name
          dfs.append(df)
      if not dfs:
          return pd.DataFrame()
      df = pd.concat(dfs, ignore_index=True)
      df["REFERENCIA"] = df["REFERENCIA"].fillna(df.get("DESCRIPCI√ìN",""))
      df = df.dropna(how="all", axis=1)
      df["FECHA"] = pd.to_datetime(df["FECHA"], format="%Y/%m/%d", errors="coerce")
      df["VALOR"] = df["VALOR"].astype(str).str.replace(",","").astype(float)
      df["Tipo"] = "Ingreso"
      df["Orden"] = ""
      df["Usuario"] = usuario
      df["Casillero"] = casillero
      df["Estado de Orden"] = ""
      out = df.rename(columns={
          "FECHA":"Fecha",
          "VALOR":"Monto",
          "REFERENCIA":"Nombre del producto"
      })[["Fecha","Tipo","Monto","Orden","Usuario","Casillero","Estado de Orden","Nombre del producto"]]
      out = out[out["Nombre del producto"]!="ABONO INTERESES AHORROS"]
      out = out[out["Monto"]>0]
      try:
          fmax = out["Fecha"].max().strftime("%Y-%m-%d")
          url = f"https://www.datos.gov.co/resource/mcec-87by.json?vigenciadesde={fmax}T00:00:00.000"
          data = requests.get(url).json()
          trm = float(data[0]["valor"]) if data and "valor" in data[0] else None
      except:
          trm = None
      out["TRM"] = trm
      return out.reset_index(drop=True)

# 2) Nueva funci√≥n para CSV ‚Äúreales‚Äù
def procesar_ingresos_clientes_csv(files: list[bytes], usuario: str, casillero: str) -> pd.DataFrame:
    dfs = []
    for up in files:
        contenido = up.read() if hasattr(up, "read") else up
        fname = getattr(up, "name", "archivo_sin_nombre")
        
        texto = None
        for codec in ("utf-8", "utf-8-sig", "latin-1", "cp1252"):
            try:
                texto = contenido.decode(codec)
                break
            except UnicodeDecodeError:
                continue
        
        if texto is None:
            import streamlit as st
            st.warning(f"‚ö†Ô∏è No se pudo decodificar '{fname}' con utf-8 / utf-8-sig / latin-1 / cp1252. Se omite.")
            continue
        
        buf = io.StringIO(texto)
        df = pd.read_csv(buf, header=None, sep=",")  # <- ya no pases 'encoding'

        # Normalizar a 10 columnas (acepta 9 o 10)
        if df.shape[1] == 9:
            df["DESCONOCIDA_6"] = None  # agrega columna vac√≠a al final
        elif df.shape[1] != 10:
            import streamlit as st
            fname = getattr(up, "name", "archivo_sin_nombre")
            st.warning(f"‚ö†Ô∏è '{fname}' tiene {df.shape[1]} columnas (esperaba 9 o 10). Se omite.")
            continue

        # Esquema fijo de 10 columnas
        df.columns = [
            "DESCRIPCI√ìN", "DESCONOCIDA_1", "DESCONOCIDA_2", "FECHA",
            "DESCONOCIDA_3", "VALOR", "DESCONOCIDA_4", "REFERENCIA",
            "DESCONOCIDA_5", "DESCONOCIDA_6"
        ]
        df["Archivo_Origen"] = getattr(up, "name", "archivo_sin_nombre")
        dfs.append(df)

    if not dfs:
        return pd.DataFrame()

    df = pd.concat(dfs, ignore_index=True)

    # Completar REFERENCIA con DESCRIPCI√ìN si viene vac√≠a
    df["REFERENCIA"] = df["REFERENCIA"].fillna(df.get("DESCRIPCI√ìN", ""))

    # Eliminar columnas completamente vac√≠as
    df = df.dropna(how="all", axis=1)

    # ---- Fecha con fallback por fila ----
    fechas_raw = df["FECHA"].astype(str).str.strip().str.zfill(8)
    f1 = pd.to_datetime(fechas_raw, format="%Y%m%d", errors="coerce")   # nuevo formato
    f2 = pd.to_datetime(fechas_raw, format="%d%m%Y", errors="coerce")   # formato viejo
    df["FECHA"] = f1.fillna(f2)
    # ------------------------------------

    # LIMPIEZA DE VALOR
    df["VALOR"] = (
        df["VALOR"]
        .astype(str)
        .str.replace(",", "", regex=False)  # elimina separador de miles si aparece
        .str.strip()
        .astype(float)
    )

    # Enriquecimiento
    df["Tipo"] = "Ingreso"
    df["Orden"] = ""
    df["Usuario"] = usuario
    df["Casillero"] = casillero
    df["Estado de Orden"] = ""

    # Renombrar y seleccionar columnas finales
    out = df.rename(columns={
        "FECHA": "Fecha",
        "VALOR": "Monto",
        "REFERENCIA": "Nombre del producto"
    })[["Fecha", "Tipo", "Monto", "Orden", "Usuario", "Casillero", "Estado de Orden", "Nombre del producto"]]

    # Filtros de negocio
    out = out[out["Nombre del producto"] != "ABONO INTERESES AHORROS"]
    out = out[out["Monto"] > 0]

    # TRM desde datos.gov.co (si posible)
    try:
        fmax = out["Fecha"].max().strftime("%Y-%m-%d")
        url = f"https://www.datos.gov.co/resource/mcec-87by.json?vigenciadesde={fmax}T00:00:00.000"
        data = requests.get(url).json()
        trm = float(data[0]["valor"]) if data and "valor" in data[0] else None
    except Exception:
        trm = None

    out["TRM"] = trm
    return out.reset_index(drop=True)

# 3) Pipeline com√∫n (extrae tu l√≥gica de post-procesamiento)

def procesar_ingresos_clientes_csv_casillero1444(files: list[bytes], usuario: str, casillero: str) -> pd.DataFrame:
    import io
    import pandas as pd
    import requests
    try:
        import streamlit as st
    except Exception:
        # Si no se ejecuta en Streamlit, definimos un stub m√≠nimo para evitar errores.
        class _Stub:
            def warning(self, *a, **k): pass
        st = _Stub()

    dfs = []
    for up in files:
        # --- Lectura robusta del archivo (bytes -> str) ---
        contenido = up.read() if hasattr(up, "read") else up
        fname = getattr(up, "name", "archivo_sin_nombre")

        texto = None
        for codec in ("utf-8", "utf-8-sig", "latin-1"):
            try:
                texto = contenido.decode(codec)
                break
            except UnicodeDecodeError:
                continue
        if texto is None:
            st.warning(f"‚ö†Ô∏è No se pudo decodificar '{fname}' con utf-8 / utf-8-sig / latin-1. Se omite.")
            continue

        buf = io.StringIO(texto)
        df = pd.read_csv(buf, header=None, sep=",")

        # --- Normalizar a 10 columnas (acepta 9 o 10) ---
        if df.shape[1] == 9:
            df["DESCONOCIDA_6"] = None  # agrega columna vac√≠a al final
        elif df.shape[1] != 10:
            st.warning(f"‚ö†Ô∏è '{fname}' tiene {df.shape[1]} columnas (esperaba 9 o 10). Se omite.")
            continue

        # Esquema fijo de 10 columnas
        df.columns = [
            "DESCRIPCI√ìN", "DESCONOCIDA_1", "DESCONOCIDA_2", "FECHA",
            "DESCONOCIDA_3", "VALOR", "DESCONOCIDA_4", "REFERENCIA",
            "DESCONOCIDA_5", "DESCONOCIDA_6"
        ]
        df["Archivo_Origen"] = fname
        dfs.append(df)

    if not dfs:
        return pd.DataFrame()

    # Concatenamos todos los DataFrames v√°lidos
    df = pd.concat(dfs, ignore_index=True)

    # REFERENCIA fallback desde DESCRIPCI√ìN
    df["REFERENCIA"] = df["REFERENCIA"].fillna(df.get("DESCRIPCI√ìN", ""))
    # Eliminar columnas completamente vac√≠as
    df = df.dropna(how="all", axis=1)

    # ---- FECHA con fallback por fila ----
    # Limpia todo lo que no sea d√≠gito, rellena a 8 y prueba YYYYMMDD; si NaT, prueba DDMMYYYY
    fechas_raw = (
        df["FECHA"].astype(str).str.strip()
        .str.replace(r"[^\d]", "", regex=True)
        .str.zfill(8)
    )
    f1 = pd.to_datetime(fechas_raw, format="%Y%m%d", errors="coerce")  # nuevo
    f2 = pd.to_datetime(fechas_raw, format="%d%m%Y", errors="coerce")  # viejo
    df["FECHA"] = f1.fillna(f2)

    # ---- VALOR a float ----
    df["VALOR"] = (
        df["VALOR"].astype(str)
        .str.replace(",", "", regex=False)  # si viniera separador de miles
        .str.strip()
        .replace({"": None})
        .astype(float)
    )

    # ===================== TRM por rango =====================
    try:
        # 1) Fecha m√°xima de transacci√≥n
        fecha_max_dt = df["FECHA"].max().date()

        # 2) Traemos TRM publicadas hasta esa fecha (orden descendente)
        punto_corte = f"{fecha_max_dt:%Y-%m-%d}T00:00:00.000"
        url = (
            "https://www.datos.gov.co/resource/mcec-87by.json?"
            f"$where=vigenciadesde <= '{punto_corte}'&$order=vigenciadesde DESC"
        )
        respuesta = requests.get(url)
        respuesta.raise_for_status()
        lista_trm = respuesta.json()

        if not lista_trm:
            st.warning("No se encontraron registros de TRM anteriores o iguales a la fecha m√°xima.")
            df_trm_para_joins = pd.DataFrame(columns=["Fecha", "TRM"])
        else:
            trm_df = pd.DataFrame(lista_trm)
            if "vigenciadesde" not in trm_df.columns or "valor" not in trm_df.columns:
                st.warning("La API de TRM no devolvi√≥ los campos esperados.")
                df_trm_para_joins = pd.DataFrame(columns=["Fecha", "TRM"])
            else:
                trm_df["vigenciadesde"] = pd.to_datetime(trm_df["vigenciadesde"]).dt.date
                trm_df["valor"] = trm_df["valor"].astype(float)
                trm_df = trm_df.rename(columns={"vigenciadesde": "Fecha", "valor": "TRM"})
                trm_df = trm_df.drop_duplicates(subset="Fecha", keep="first")
                trm_df = trm_df.sort_values("Fecha", ascending=False).set_index("Fecha")

                # 3) Rango de fechas para ffill
                fecha_min_trm = trm_df.index.min()
                fecha_min_tx = df["FECHA"].dt.date.min()
                fecha_inicio_rango = min(fecha_min_trm, fecha_min_tx)
                fecha_fin_rango = fecha_max_dt

                rango_fechas = pd.date_range(start=fecha_inicio_rango, end=fecha_fin_rango, freq="D").date
                df_trm_full = pd.DataFrame(index=rango_fechas, columns=["TRM"])

                # 7) Colocar TRM conocida en d√≠as disponibles
                for dia in trm_df.index:
                    df_trm_full.loc[dia, "TRM"] = trm_df.loc[dia, "TRM"]

                # 8) Rellenar hacia adelante
                df_trm_full["TRM"] = df_trm_full["TRM"].ffill()

                # 9) Preparar para merge
                df_trm_para_joins = df_trm_full.reset_index().rename(columns={"index": "Fecha"})
    except Exception as e:
        st.warning(f"No se pudo obtener TRM: {e}")
        df_trm_para_joins = pd.DataFrame(columns=["Fecha", "TRM"])
    # =========================================================

    # Preparar columna Fecha (date) y merge con TRM
    df["Fecha"] = df["FECHA"].dt.date
    df = df.merge(df_trm_para_joins, on="Fecha", how="left")

    # Calcular VALOR en USD (como en tu ejemplo, usando TRM + 100) y evitar divisi√≥n por nulo
    # Si TRM es NaN, el resultado ser√° NaN; puedes decidir si llenar con 0 u otro valor.
    df["VALOR_USD"] = df["TRM"]
    df.loc[df["TRM"].notna(), "VALOR_USD"] = df.loc[df["TRM"].notna(), "VALOR"] / (df.loc[df["TRM"].notna(), "TRM"] + 100)

    # Asignar columnas est√°ndar
    df["Tipo"] = "Ingreso"
    df["Orden"] = ""
    df["Usuario"] = usuario
    df["Casillero"] = casillero
    df["Estado de Orden"] = ""

    # Construcci√≥n final
    out = df.rename(columns={
        "VALOR_USD": "Monto",
        "REFERENCIA": "Nombre del producto"
    })[["Fecha", "Tipo", "Monto", "Orden", "Usuario", "Casillero", "Estado de Orden", "Nombre del producto", "TRM"]]

    # Filtros de negocio
    out = out[out["Nombre del producto"] != "ABONO INTERESES AHORROS"]
    out = out[out["Monto"] > 0]

    return out.reset_index(drop=True)


def procesar_ingresos_davivienda(files: list, usuario: str, casillero: str) -> pd.DataFrame:
    """
    Procesa archivos Excel de Davivienda (UploadedFile de Streamlit).
    Toma ‚ÄúDescripci√≥n motivo‚Äù (columna REFERENCIA) como Nombre del producto, 
    pero si est√° vac√≠a o nula, utiliza ‚ÄúReferencia 1‚Äù como fallback.
    Devuelve un DataFrame con la misma estructura que la funci√≥n de Bancolombia.
    """
    dfs = []
    for up in files:
        try:
            # 1) Leer Excel directamente
            df_excel = pd.read_excel(up)
        except Exception as e:
            st.warning(f"‚ùå No se pudo leer '{up.name}' como Excel: {e}")
            continue

        # 2) Renombrar columnas clave
        mapeo = {
            "Fecha de Sistema":   "FECHA",
            "Valor Total":         "VALOR",
            "Descripci√≥n motivo":  "REFERENCIA"
        }
        df_excel = df_excel.rename(columns=mapeo)

        # 3) Verificar columnas m√≠nimas
        faltantes = [
            c for c in ["FECHA", "VALOR", "REFERENCIA", "Transacci√≥n", "Referencia 1"]
            if c not in df_excel.columns
        ]
        if faltantes:
            st.warning(f"‚ö†Ô∏è En '{up.name}' faltan columnas: {faltantes}. Se omitir√° este archivo.")
            continue

        # 4) Convertir FECHA a datetime
        df_excel["FECHA"] = pd.to_datetime(
            df_excel["FECHA"],
            format="%d/%m/%Y",
            errors="coerce"
        )
        n_nat = int(df_excel["FECHA"].isna().sum())
        if n_nat > 0:
            st.warning(f"‚ö†Ô∏è En '{up.name}', {n_nat} filas tienen FECHA inv√°lida y ser√°n NaT.")

        # 5) Limpiar VALOR: quitar "$", espacios, separador de miles y coma decimal ‚Üí punto
        df_excel["VALOR"] = (
            df_excel["VALOR"]
            .astype(str)
            .str.replace("$", "",     regex=False)
            .str.replace(" ", "",     regex=False)
            .str.replace(".", "",     regex=False)
            .str.replace(",", ".",    regex=False)
        )
        df_excel["VALOR"] = pd.to_numeric(df_excel["VALOR"], errors="coerce")
        n_nanval = int(df_excel["VALOR"].isna().sum())
        if n_nanval > 0:
            st.warning(f"‚ö†Ô∏è En '{up.name}', {n_nanval} filas tienen VALOR inv√°lido (NaN).")

        # 6) Ajustar signo: ‚ÄúNota D√©bito‚Äù ‚Üí valor negativo
        mask_debito = (
            df_excel["Transacci√≥n"]
            .astype(str)
            .str.strip()
            .str.upper() == "NOTA D√âBITO"
        )
        df_excel.loc[mask_debito, "VALOR"] *= -1

        # 7) Construir ‚ÄúNombre del producto‚Äù:
        #    - Si REFERENCIA no est√° vac√≠a (ni NaN), usarla.
        #    - Si REFERENCIA est√° vac√≠a/NaN, usar ‚ÄúReferencia 1‚Äù.
        def elegir_nombre(row):
            ref = str(row["REFERENCIA"]).strip()
            if ref and ref.upper() != "NAN":
                return ref
            # Si REF vac√≠o o ‚Äúnan‚Äù, caemos en Referencia 1:
            return str(row["Referencia 1"]).strip()

        df_excel["Nombre del producto"] = df_excel.apply(elegir_nombre, axis=1)

        # 8) Crear DataFrame temporal para merge_asof
        df_sel = pd.DataFrame({
            "Fecha": df_excel["FECHA"],
            "ValorCOP": df_excel["VALOR"],
            "Nombre del producto": df_excel["Nombre del producto"],
            "Archivo_Origen": up.name
        }).dropna(subset=["Fecha", "ValorCOP"])

        dfs.append(df_sel)

    # 9) Si no hay nada v√°lido, retornar vac√≠o
    if not dfs:
        return pd.DataFrame()

    # 10) Concatenar transacciones Davivienda limpias
    df_trans = pd.concat(dfs, ignore_index=True)

    # 11) Obtener TRM hist√≥rica (misma l√≥gica que Bancolombia)
    try:
        fecha_max_tx = df_trans["Fecha"].max().date()
        punto_corte = fecha_max_tx.strftime("%Y-%m-%dT00:00:00.000")
        url = (
            "https://www.datos.gov.co/resource/mcec-87by.json?"
            f"$where=vigenciadesde <= '{punto_corte}'"
            "&$order=vigenciadesde DESC"
        )
        respuesta = requests.get(url)
        respuesta.raise_for_status()
        lista_trm = respuesta.json()

        if not lista_trm:
            st.warning("No se encontraron registros de TRM anteriores o iguales a la fecha m√°xima.")
            trm_df = pd.DataFrame(columns=["Fecha", "TRM"])
        else:
            trm_df = pd.DataFrame(lista_trm)
            trm_df["Fecha"] = pd.to_datetime(trm_df["vigenciadesde"], errors="coerce")
            trm_df["TRM"]   = trm_df["valor"].astype(float)
            trm_df = trm_df[["Fecha", "TRM"]]
            trm_df = trm_df.drop_duplicates(subset="Fecha", keep="first")
            trm_df = trm_df.sort_values("Fecha").reset_index(drop=True)
    except Exception as e:
        st.warning(f"No se pudo obtener TRM: {e}")
        trm_df = pd.DataFrame(columns=["Fecha", "TRM"])

    # 12) Merge_asof para asignar TRM a cada transacci√≥n
    df_trans = df_trans.sort_values("Fecha").reset_index(drop=True)
    trm_df   = trm_df.sort_values("Fecha").reset_index(drop=True)

    df_merged = pd.merge_asof(
        df_trans,
        trm_df,
        on="Fecha",
        direction="backward"
    )

    # 13) Calcular Monto (en USD)
    df_merged["Monto"] = df_merged["ValorCOP"] / (df_merged["TRM"] + 100)

    # 14) A√±adir columnas fijas para homogeneizar con Bancolombia
    df_merged["Tipo"] = "Ingreso"
    df_merged["Orden"] = ""
    df_merged["Usuario"] = usuario
    df_merged["Casillero"] = casillero
    df_merged["Estado de Orden"] = ""

    # 15) DataFrame final con mismas columnas que Bancolombia
    out = df_merged[[
        "Fecha",
        "Tipo",
        "Monto",
        "Orden",
        "Usuario",
        "Casillero",
        "Estado de Orden",
        "Nombre del producto",
        "TRM"
    ]]

    # 16) Filtrar movimientos no deseados: ‚ÄúABONO INTERESES AHORROS‚Äù y montos ‚â§ 0
    out = out[out["Nombre del producto"] != "ABONO INTERESES AHORROS"]
    out = out[out["Monto"] > 0]

    return out.reset_index(drop=True)
def main():
    st.title("üìä Conciliaciones Mayoristas")

    # 1) Egresos
    st.header("1) Egresos (Compras)")
    compras = st.file_uploader("Sube archivos de COMPRAS", type=["xls","xlsx"], accept_multiple_files=True)
    egresos = {}
    if compras:
        dfc = pd.concat([pd.read_excel(f) for f in compras], ignore_index=True)
        egresos = procesar_egresos(dfc)
        tabs = st.tabs(list(egresos.keys()))
        for tab, key in zip(tabs, egresos):
            with tab:
                df = egresos[key]
                if df.empty:
                    st.info("Sin egresos")
                else:
                    st.dataframe(df, use_container_width=True)
    else:
        st.info("üìÇ A√∫n no subes Compras")

    st.markdown("---")

    # 2) Ingresos Extra
    st.header("2) Ingresos Extra")
    extra = st.file_uploader("Sube archivo de INGRESOS EXTRA", type=["xls","xlsx"])
    ingresos_extra = {}
    if extra:
        hojas = pd.read_excel(extra, sheet_name=None)
        ingresos_extra = procesar_ingresos_extra(hojas)
        tabs2 = st.tabs(list(ingresos_extra.keys()))
        for tab, key in zip(tabs2, ingresos_extra):
            with tab:
                df = ingresos_extra[key]
                if df.empty:
                    st.info("Sin datos")
                else:
                    st.dataframe(df, use_container_width=True)
    else:
        st.info("üìÇ A√∫n no subes Ingresos Extra")

    st.markdown("---")

   # 3) Ingresos Nathalia Ospina (CA1633)
    st.header("3) Ingresos Nathalia Ospina (CA1633)")
    nat_files = st.file_uploader(
        "Sube archivos .xls y .csv de Nathalia", 
        type=["xls", "xlsx", "csv"], 
        accept_multiple_files=True
    )
    ingresos_nath = {}
    
    if nat_files:
        # Separar por extensiones
        xls_files = [f for f in nat_files if f.name.lower().endswith((".xls", ".xlsx"))]
        csv_files = [f for f in nat_files if f.name.lower().endswith(".csv")]
    
        dfs = []
        if xls_files:
            df_xls = procesar_ingresos_clientes_xls(xls_files, "Nathalia Ospina", "1633")
            dfs.append(df_xls)
        if csv_files:
            df_csv = procesar_ingresos_clientes_csv(csv_files, "Nathalia Ospina", "1633")
            dfs.append(df_csv)
    
        # Concatenar resultados o crear DataFrame vac√≠o
        if dfs:
            df_nat = pd.concat(dfs, ignore_index=True)
        else:
            df_nat = pd.DataFrame()
    
        ingresos_nath["ingresos_1633"] = df_nat
    
        # Mostrar en la app
        if df_nat.empty:
            st.info("Sin movimientos v√°lidos")
        else:
            st.dataframe(df_nat, use_container_width=True)
    else:
        st.info("üìÇ No subes archivos de Nathalia")
    
    st.markdown("---")

    # 4) Ingresos Elvis (CA11591)
    st.header("4) Ingresos Elvis (CA11591)")
    elv_files = st.file_uploader(
        "Sube archivos .xls y .csv de Elvis",
        type=["xls", "xlsx", "csv"],
        accept_multiple_files=True
    )
    ingresos_elv = {}
    
    if elv_files:
        # Separar por extensi√≥n
        xls_files = [f for f in elv_files if f.name.lower().endswith((".xls", ".xlsx"))]
        csv_files = [f for f in elv_files if f.name.lower().endswith(".csv")]
    
        dfs = []
        if xls_files:
            df_xls = procesar_ingresos_clientes_xls(xls_files, "Elvis", "11591")
            dfs.append(df_xls)
        if csv_files:
            df_csv = procesar_ingresos_clientes_csv(csv_files, "Elvis", "11591")
            dfs.append(df_csv)
    
        # Concatenar resultados o crear DataFrame vac√≠o
        if dfs:
            df_elv = pd.concat(dfs, ignore_index=True)
        else:
            df_elv = pd.DataFrame()
    
        ingresos_elv["ingresos_11591"] = df_elv
    
        # Mostrar en la app
        if df_elv.empty:
            st.info("Sin movimientos v√°lidos")
        else:
            st.dataframe(df_elv, use_container_width=True)
    else:
        st.info("üìÇ No subes archivos de Elvis")
    
    st.markdown("---")
    
    st.header("5) Ingresos Maria Moises (CA1444)")
    moises_files = st.file_uploader(
        "Sube archivos .csv de Maria Moises (Bancolombia o Davivienda)", 
        type=["xls", "xlsx", "csv"], 
        accept_multiple_files=True
    )
    

    
    ingresos_moises = {}

    if moises_files:
        csv_banco   = []
        excel_davi  = []  # antes se llamaba csv_davi

        for file in moises_files:
          nombre = file.name.lower()
          # Si es un CSV lo metemos en Bancolombia:
          if nombre.endswith(".csv"):
              csv_banco.append(file)

          # Si es un Excel (.xlsx o .xls), lo metemos en Davivienda:
          elif nombre.endswith(".xlsx") or nombre.endswith(".xls"):
              excel_davi.append(file)

          else:
              st.warning(f"‚ö†Ô∏è '{file.name}' no es ni CSV ni Excel v√°lido, se omitir√°.")

        dfs = []
        if csv_banco:
          df_banco = procesar_ingresos_clientes_csv_casillero1444(
              csv_banco, "Maria Moises", "1444"
          )
          dfs.append(df_banco)

        if excel_davi:
          # Llamamos ahora a la funci√≥n procesar_ingresos_davivienda para los Excel
          df_davi = procesar_ingresos_davivienda(
              excel_davi, "Maria Moises", "1444"
          )
          dfs.append(df_davi)

        if dfs:
          df_moises = pd.concat(dfs, ignore_index=True)
        else:
          df_moises = pd.DataFrame()

        ingresos_moises["ingresos_1444"] = df_moises

        if df_moises.empty:
          st.info("Sin movimientos v√°lidos")
        else:
          st.dataframe(df_moises, use_container_width=True)
    else:
      st.info("üìÇ No subes archivos de Maria Moises")

    st.markdown("---")

    
    
    
    
    # 5) Conciliaciones
    # 5) Conciliaciones Finales
    st.header("6) Conciliaciones Finales")
    
    casilleros = ["9444", "14856", "11591", "1444", "1633"]
    conciliaciones = {}
    
    for cas in casilleros:
        key_ing = f"ingresos_{cas}"
    
        # 2) Obtener cada fuente de ingresos en orden de prioridad
        ing_n = ingresos_nath.get(key_ing)
        ing_e = ingresos_elv.get(key_ing)
        ing_m = ingresos_moises.get(key_ing)
    
        if ing_n is not None and not ing_n.empty:
            inc = ing_n
        elif ing_e is not None and not ing_e.empty:
            inc = ing_e
        elif ing_m is not None and not ing_m.empty:
            inc = ing_m
        else:
            inc = None
    
        # EGRESOS
        egr = egresos.get(f"egresos_{cas}")
    
        # EXTRA (ingresos extra)
        ext = ingresos_extra.get(f"extra_{cas}")
    
        # 3) Armar la lista de DataFrames v√°lidos
        frames = []
        for df in (inc, egr, ext):
            if df is not None and not df.empty:
                frames.append(df)
    
        # 4) Guardar la conciliaci√≥n (si no hay nada, vac√≠o)
        if frames:
            conciliaciones[f"conciliacion_{cas}"] = pd.concat(frames, ignore_index=True)
        else:
            conciliaciones[f"conciliacion_{cas}"] = pd.DataFrame()
    
    # 5) Mostrar en pesta√±as
    tabs5 = st.tabs(list(conciliaciones.keys()))
    for tab, key in zip(tabs5, conciliaciones.keys()):
        with tab:
            dfc = conciliaciones[key]
            if dfc.empty:
                st.info("‚õî Sin movimientos para este casillero")
            else:
                st.dataframe(dfc, use_container_width=True)

    st.markdown("---")


    st.markdown("---")

    # 6) Hist√≥rico: carga y actualizaci√≥n
    st.header("7) Actualizar Hist√≥rico") 
    hist_file = st.file_uploader("Sube tu archivo HIST√ìRICO EXISTENTE", type=["xls","xlsx"])
    if hist_file:
        historico = pd.read_excel(hist_file, sheet_name=None)
        fecha_carga = pd.Timestamp.today().strftime("%Y-%m-%d")
        # actualizar cada conciliaci√≥n
        for clave, df_nuevo in conciliaciones.items():
            cas = clave.replace("conciliacion_","")
            dfn = df_nuevo.copy()
            dfn["Fecha de Carga"] = fecha_carga
            if dfn.empty: continue
            usuario = dfn["Usuario"].iloc[0]
            cnum = dfn["Casillero"].iloc[0]
            hoja = next((h for h in historico if h.startswith(cas)), None)
            if hoja:
                combinado = pd.concat([historico[hoja], dfn], ignore_index=True)
            else:
                combinado = dfn
                hoja = f"{cas} - sin_nombre"
            combinado["Orden"] = combinado["Orden"].astype(str)    
            # eliminar duplicados egresos
            mask_e = combinado["Tipo"]=="Egreso"
            egrs = combinado[mask_e].drop_duplicates(subset=["Orden","Tipo"])
            otros = combinado[~mask_e]
            combinado = pd.concat([otros,egrs], ignore_index=True)
            combinado["Monto"] = pd.to_numeric(combinado["Monto"], errors="coerce")
            # eliminar duplicados extra
            if "Motivo" in combinado.columns:
                mask_x = combinado["Motivo"]=="Ingreso_extra"
                iex = combinado[mask_x].drop_duplicates(subset=["Orden","Motivo"])
                ot = combinado[~mask_x]
                combinado = pd.concat([ot,iex], ignore_index=True)
            # completar ingresos nulos
            mask_n = (combinado["Tipo"]=="Ingreso") & combinado["Monto"].isna()
            for i,row in combinado[mask_n].iterrows():
                o = row["Orden"]
                match = combinado[(combinado["Tipo"]=="Egreso") & (combinado["Orden"]==o)]
                if not match.empty:
                    combinado.at[i,"Monto"] = match["Monto"].iloc[0]
            # balance y fila total
            tot_i = combinado[combinado["Tipo"]=="Ingreso"]["Monto"].sum()
            tot_e = combinado[combinado["Tipo"]=="Egreso"]["Monto"].sum()
            bal = tot_i - tot_e
            estado = "Al d√≠a" if bal>=0 else "Alerta"
            fila = pd.DataFrame([{
                "Fecha": fecha_carga,
                "Tipo":"Total",
                "Monto":bal,
                "Orden":estado,
                "TRM":"",
                "Usuario":usuario,
                "Casillero":cnum,
                "Fecha de Carga":fecha_carga,
                "Estado de Orden":"",
                "Nombre del producto":""
            }])
            historico[hoja] = pd.concat([combinado,fila], ignore_index=True)
        # generar excel en memoria
        buf = io.BytesIO()
        with pd.ExcelWriter(buf, engine="openpyxl") as w:
            for h,dfh in historico.items():
                w.book.create_sheet(h[:31])
                dfh.to_excel(w, sheet_name=h[:31], index=False)
        buf.seek(0)
        data_bytes = buf.read()

        # 1) Bot√≥n de descarga local
        st.download_button(
            "‚¨áÔ∏è Descargar Hist√≥rico Actualizado",
            data=data_bytes,  # <-- aqu√≠, usa data_bytes
            file_name=f"{pd.Timestamp.today().strftime('%Y%m%d')}_Historico_mayoristas.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

        # 2) Subida autom√°tica a Dropbox
        upload_to_dropbox(data_bytes)
    else:
        st.info("üìÇ A√∫n no subes tu hist√≥rico")

    st.caption("Desarrollado con ‚ù§Ô∏è y Streamlit")

if __name__=="__main__":
    main()
